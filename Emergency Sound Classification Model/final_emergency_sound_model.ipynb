{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Final Emergency Sound Classification Model\n", "This notebook contains the full code for the best-performing model:\n", "- CNN using 128-band Mel Spectrograms\n", "- SpecAugment\n", "- Class weights\n", "- Learning rate scheduler\n", "- Achieved 94% accuracy"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Mount Google Drive\n", "from google.colab import drive\n", "drive.mount('/content/drive')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Install dependencies\n", "!pip install audiomentations"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Import libraries\n", "import os\n", "import numpy as np\n", "import librosa\n", "import random\n", "from audiomentations import Compose, PitchShift, TimeStretch, Gain, Shift\n", "from sklearn.preprocessing import LabelEncoder\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.metrics import classification_report\n", "from sklearn.utils import class_weight\n", "import matplotlib.pyplot as plt\n", "from tensorflow.keras.utils import to_categorical, Sequence\n", "from tensorflow.keras.models import Sequential\n", "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n", "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Paths and constants\n", "DATA_PATH = \"/content/drive/MyDrive/Split_Dataset\"\n", "SAMPLE_RATE = 16000\n", "DURATION = 3\n", "SAMPLES_PER_TRACK = SAMPLE_RATE * DURATION\n", "N_MELS = 128"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Augmentation\n", "AUGMENT = Compose([\n", "    PitchShift(min_semitones=-2, max_semitones=2, p=0.5),\n", "    TimeStretch(min_rate=0.8, max_rate=1.2, p=0.5),\n", "    Gain(min_gain_db=-6, max_gain_db=6, p=0.5),\n", "    Shift(min_fraction=-0.1, max_fraction=0.1, p=0.5)\n", "])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Mel spectrogram extraction with SpecAugment\n", "def extract_mel_spectrogram(file_path, apply_augment=False):\n", "    try:\n", "        audio, sr = librosa.load(file_path, sr=SAMPLE_RATE, duration=DURATION)\n", "        if len(audio.shape) > 1:\n", "            audio = librosa.to_mono(audio)\n", "        if len(audio) < SAMPLES_PER_TRACK:\n", "            audio = np.pad(audio, (0, SAMPLES_PER_TRACK - len(audio)))\n", "        else:\n", "            audio = audio[:SAMPLES_PER_TRACK]\n", "        if apply_augment:\n", "            audio = AUGMENT(samples=audio, sample_rate=sr)\n", "        mel = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=N_MELS)\n", "        mel_db = librosa.power_to_db(mel, ref=np.max)\n", "        return mel_db\n", "    except Exception as e:\n", "        print(f\"Error: {file_path} | {e}\")\n", "        return None\n", "\n", "def apply_specaugment(mel, time_mask_param=15, freq_mask_param=10):\n", "    m = mel.copy()\n", "    f = random.randint(0, freq_mask_param)\n", "    f0 = random.randint(0, m.shape[0] - f)\n", "    m[f0:f0+f, :] = 0\n", "    t = random.randint(0, time_mask_param)\n", "    t0 = random.randint(0, m.shape[1] - t)\n", "    m[:, t0:t0+t] = 0\n", "    return m"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Data Generator\n", "class AudioDataGenerator(Sequence):\n", "    def __init__(self, file_paths, labels, batch_size=32, augment=False, shuffle=True):\n", "        self.file_paths = file_paths\n", "        self.labels = labels\n", "        self.batch_size = batch_size\n", "        self.augment = augment\n", "        self.shuffle = shuffle\n", "        self.on_epoch_end()\n", "\n", "    def __len__(self):\n", "        return int(np.ceil(len(self.file_paths) / self.batch_size))\n", "\n", "    def __getitem__(self, index):\n", "        batch_paths = self.file_paths[index*self.batch_size:(index+1)*self.batch_size]\n", "        batch_labels = self.labels[index*self.batch_size:(index+1)*self.batch_size]\n", "        X, y = [], []\n", "\n", "        for path, label in zip(batch_paths, batch_labels):\n", "            mel = extract_mel_spectrogram(path, apply_augment=self.augment)\n", "            if mel is not None and mel.shape[1] == 94:\n", "                if self.augment:\n", "                    mel = apply_specaugment(mel)\n", "                X.append(mel[..., np.newaxis])\n", "                y.append(label)\n", "\n", "        if len(X) < 2:\n", "            return self.__getitem__((index + 1) % self.__len__())\n", "\n", "        return np.array(X), np.array(y)\n", "\n", "    def on_epoch_end(self):\n", "        if self.shuffle:\n", "            zipped = list(zip(self.file_paths, self.labels))\n", "            random.shuffle(zipped)\n", "            self.file_paths, self.labels = zip(*zipped)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Prepare data\n", "file_paths = []\n", "labels = []\n", "\n", "for label in os.listdir(DATA_PATH):\n", "    folder = os.path.join(DATA_PATH, label)\n", "    if os.path.isdir(folder):\n", "        for file in os.listdir(folder):\n", "            if file.endswith('.wav'):\n", "                file_paths.append(os.path.join(folder, file))\n", "                labels.append(label)\n", "\n", "le = LabelEncoder()\n", "labels_encoded = le.fit_transform(labels)\n", "labels_onehot = to_categorical(labels_encoded)\n", "\n", "train_paths, test_paths, train_labels, test_labels = train_test_split(\n", "    file_paths, labels_onehot, test_size=0.2, stratify=labels_encoded, random_state=42\n", ")\n", "\n", "train_gen = AudioDataGenerator(train_paths, train_labels, augment=True)\n", "val_gen = AudioDataGenerator(test_paths, test_labels, augment=False)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Define model\n", "model = Sequential([\n", "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 94, 1)),\n", "    BatchNormalization(),\n", "    MaxPooling2D((2, 2)),\n", "    Dropout(0.3),\n", "\n", "    Conv2D(64, (3, 3), activation='relu'),\n", "    BatchNormalization(),\n", "    MaxPooling2D((2, 2)),\n", "    Dropout(0.3),\n", "\n", "    Conv2D(128, (3, 3), activation='relu'),\n", "    BatchNormalization(),\n", "    MaxPooling2D((2, 2)),\n", "    Dropout(0.3),\n", "\n", "    Flatten(),\n", "    Dense(128, activation='relu'),\n", "    BatchNormalization(),\n", "    Dropout(0.3),\n", "\n", "    Dense(labels_onehot.shape[1], activation='softmax')\n", "])\n", "\n", "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n", "model.summary()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Compute class weights\n", "y_train_labels = np.argmax(train_labels, axis=1)\n", "class_weights = class_weight.compute_class_weight(class_weight='balanced',\n", "                                                  classes=np.unique(y_train_labels),\n", "                                                  y=y_train_labels)\n", "class_weight_dict = dict(enumerate(class_weights))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Train model with callbacks\n", "callbacks = [\n", "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n", "    ModelCheckpoint('/content/drive/MyDrive/best_final_model.h5', save_best_only=True),\n", "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, min_lr=1e-6)\n", "]\n", "\n", "history = model.fit(\n", "    train_gen,\n", "    validation_data=val_gen,\n", "    epochs=30,\n", "    callbacks=callbacks,\n", "    class_weight=class_weight_dict\n", ")"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": ""}}, "nbformat": 4, "nbformat_minor": 5}